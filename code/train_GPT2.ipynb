{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5537,
     "status": "ok",
     "timestamp": 1665057392480,
     "user": {
      "displayName": "tsuka naga",
      "userId": "01610637380750766050"
     },
     "user_tz": -540
    },
    "id": "IMnymRDLe0hi",
    "outputId": "412253d1-5df1-45aa-8b0c-fa3b7f22be1b"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "paths = [\"name_dataset.txt\"]\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=20_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1665057392481,
     "user": {
      "displayName": "tsuka naga",
      "userId": "01610637380750766050"
     },
     "user_tz": -540
    },
    "id": "EIS-irI0f32P",
    "outputId": "d1216336-db7d-4508-aff5-0b2642afff7b"
   },
   "outputs": [],
   "source": [
    "#!mkdir tokenizer_wiki_2\n",
    "tokenizer.save_model(\"./exp_wiki/tokenizer_wiki_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1665057392482,
     "user": {
      "displayName": "tsuka naga",
      "userId": "01610637380750766050"
     },
     "user_tz": -540
    },
    "id": "tKVWB8WShT-z"
   },
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./exp_wiki/tokenizer_wiki_/vocab.json\",\n",
    "    \"./exp_wiki/tokenizer_wiki_/merges.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1061,
     "status": "ok",
     "timestamp": 1665057393537,
     "user": {
      "displayName": "tsuka naga",
      "userId": "01610637380750766050"
     },
     "user_tz": -540
    },
    "id": "VNZZs-r6iKAV",
    "outputId": "b80bc8e6-bd4a-4903-b127-43aa37251f47"
   },
   "outputs": [],
   "source": [
    "# GPU availability\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1665057393537,
     "user": {
      "displayName": "tsuka naga",
      "userId": "01610637380750766050"
     },
     "user_tz": -540
    },
    "id": "hUtjY2iFuqk_"
   },
   "outputs": [],
   "source": [
    "#random seed\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1665057393955,
     "user": {
      "displayName": "tsuka naga",
      "userId": "01610637380750766050"
     },
     "user_tz": -540
    },
    "id": "LTXXutqeDzPi"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Config, GPT2Tokenizer\n",
    "\n",
    "# Initializing a GPT2 configuration\n",
    "configuration = GPT2Config(vocab_size=52_000)\n",
    "model = GPT2LMHeadModel(config=configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1665057393956,
     "user": {
      "displayName": "tsuka naga",
      "userId": "01610637380750766050"
     },
     "user_tz": -540
    },
    "id": "4keFBUjQFOD1"
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./exp_wiki/\", max_len=512)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2809,
     "status": "ok",
     "timestamp": 1665057396762,
     "user": {
      "displayName": "tsuka naga",
      "userId": "01610637380750766050"
     },
     "user_tz": -540
    },
    "id": "BzMqR-dzF4Ro"
   },
   "outputs": [],
   "source": [
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"data_file.txt\",\n",
    "    block_size=128,\n",
    ")\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "id": "YpvnFFmZJD-N",
    "outputId": "5edb665a-1dfc-44eb-e1af-39a3dc75c5b1"
   },
   "outputs": [],
   "source": [
    "from transformers import TextDataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "#curriculum: (block_size, batch_size, end_steps)\n",
    "curriculum = [\n",
    "    (64, 8, 10_000),\n",
    "    (128, 8, 20_000),\n",
    "    (256, 8, 30_000),\n",
    "    (512, 8, 60_000),\n",
    "]\n",
    "\n",
    "last_steps = 0\n",
    "is_first_phase = True\n",
    "\n",
    "for block_size, batch_size, end_steps in curriculum:\n",
    "  print(f\"######## Block size = {block_size}, Batch size = {batch_size} ########\")\n",
    "  #Build our training and evaluation datasets\n",
    "  train_dataset = TextDataset(\n",
    "      tokenizer=tokenizer,\n",
    "      file_path=\"dataset_path_train.txt\",\n",
    "      block_size=block_size,\n",
    "  )\n",
    "  eval_dataset = TextDataset(\n",
    "      tokenizer=tokenizer,\n",
    "      file_path=\"dataset_path_eval.txt\",\n",
    "      block_size=512,\n",
    "  )\n",
    "  #Set training arguments\n",
    "  training_args = TrainingArguments(\n",
    "      output_dir=\"log\", #mkdir log if necessary\n",
    "      overwrite_output_dir=True,\n",
    "      num_train_epochs=1,\n",
    "      per_gpu_train_batch_size=8,\n",
    "      save_steps=10_000,\n",
    "      save_total_limit=2,\n",
    "  )\n",
    "\n",
    "  trainer = Trainer(\n",
    "      model=model,\n",
    "      args=training_args,\n",
    "      data_collator=data_collator,\n",
    "      train_dataset=train_dataset,\n",
    "      eval_dataset=eval_dataset,\n",
    "  )\n",
    "  #train a language model\n",
    "  if is_first_phase:\n",
    "    trainer.train()\n",
    "    is_first_phase = False\n",
    "  else:\n",
    "    trainer.train(f\"log/checkpoint-{last_steps}\")\n",
    "  last_steps = end_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDNgPls7_l13"
   },
   "outputs": [],
   "source": [
    "#mkdir log if necessary\n",
    "trainer.save_model(\"./exp_wiki/insert_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, prompt, max_tokens, temperature=0.7):\n",
    "    model.eval()\n",
    "    for _ in range(max_tokens):\n",
    "        prompt = prompt[:, :128]\n",
    "        logits = model(prompt)\n",
    "        logits = logits[0][:, -1, :] / temperature\n",
    "        logit_probs = nn.functional.softmax(logits, dim=-1)\n",
    "        next_prompt = torch.multinomial(logit_probs, num_samples=1)\n",
    "        prompt = torch.cat((prompt, next_prompt), dim=1)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 128\n",
    "prompt = tokenizer.encode(\"In my opinion\", return_tensors='pt').to('cuda')\n",
    "generated_text = generate(model, prompt, max_tokens, temperature=0.7)\n",
    "generated_text = tokenizer.decode(generated_text[0])\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
